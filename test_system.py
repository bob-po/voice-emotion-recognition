#!/usr/bin/env python3
"""
è¯­éŸ³æƒ…ç»ªè¯†åˆ«ç³»ç»Ÿæµ‹è¯•è„šæœ¬
"""

import os
import sys
import numpy as np
import tempfile
import soundfile as sf
from emotion_speech_recognition import EmotionSpeechRecognition

def create_test_audio(duration=3, sample_rate=16000, frequency=440):
    """
    åˆ›å»ºæµ‹è¯•éŸ³é¢‘æ–‡ä»¶
    
    Args:
        duration: éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
        sample_rate: é‡‡æ ·ç‡
        frequency: é¢‘ç‡ï¼ˆHzï¼‰
        
    Returns:
        éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    """
    # ç”Ÿæˆæ­£å¼¦æ³¢
    t = np.linspace(0, duration, int(sample_rate * duration), False)
    audio = np.sin(2 * np.pi * frequency * t) * 0.3
    
    # æ·»åŠ ä¸€äº›éšæœºå™ªå£°æ¨¡æ‹ŸçœŸå®è¯­éŸ³
    noise = np.random.normal(0, 0.01, len(audio))
    audio = audio + noise
    
    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
    temp_file = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)
    sf.write(temp_file.name, audio, sample_rate)
    
    return temp_file.name

def test_model_loading():
    """
    æµ‹è¯•æ¨¡å‹åŠ è½½
    """
    print("ğŸ§ª æµ‹è¯•1: æ¨¡å‹åŠ è½½")
    try:
        recognizer = EmotionSpeechRecognition()
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        return recognizer
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None

def test_audio_preprocessing(recognizer):
    """
    æµ‹è¯•éŸ³é¢‘é¢„å¤„ç†
    """
    print("\nğŸ§ª æµ‹è¯•2: éŸ³é¢‘é¢„å¤„ç†")
    try:
        # åˆ›å»ºæµ‹è¯•éŸ³é¢‘
        test_audio_path = create_test_audio()
        print(f"ğŸ“ åˆ›å»ºæµ‹è¯•éŸ³é¢‘: {test_audio_path}")
        
        # æµ‹è¯•é¢„å¤„ç†
        audio = recognizer.preprocess_audio(test_audio_path)
        if audio is not None:
            print(f"âœ… éŸ³é¢‘é¢„å¤„ç†æˆåŠŸï¼Œé•¿åº¦: {len(audio)} é‡‡æ ·ç‚¹")
        else:
            print("âŒ éŸ³é¢‘é¢„å¤„ç†å¤±è´¥")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.unlink(test_audio_path)
        return test_audio_path
        
    except Exception as e:
        print(f"âŒ éŸ³é¢‘é¢„å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        return None

def test_emotion_prediction(recognizer, audio_path):
    """
    æµ‹è¯•æƒ…ç»ªé¢„æµ‹
    """
    print("\nğŸ§ª æµ‹è¯•3: æƒ…ç»ªé¢„æµ‹")
    try:
        # é‡æ–°åˆ›å»ºæµ‹è¯•éŸ³é¢‘ï¼ˆå› ä¸ºä¹‹å‰åˆ é™¤äº†ï¼‰
        test_audio_path = create_test_audio()
        
        # é¢„æµ‹æƒ…ç»ª
        result = recognizer.predict_emotion(test_audio_path)
        
        if "error" in result:
            print(f"âŒ æƒ…ç»ªé¢„æµ‹å¤±è´¥: {result['error']}")
            return False
        
        print("âœ… æƒ…ç»ªé¢„æµ‹æˆåŠŸ")
        print(f"ğŸ¯ é¢„æµ‹æƒ…ç»ª: {result['predicted_emotion']}")
        print(f"ğŸ“Š ç½®ä¿¡åº¦: {result['confidence']:.3f}")
        
        print("ğŸ“ˆ æ‰€æœ‰æƒ…ç»ªæ¦‚ç‡:")
        for emotion, prob in result['all_emotions']:
            print(f"  - {emotion}: {prob:.3f} ({prob*100:.1f}%)")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.unlink(test_audio_path)
        return True
        
    except Exception as e:
        print(f"âŒ æƒ…ç»ªé¢„æµ‹æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_array_prediction(recognizer):
    """
    æµ‹è¯•æ•°ç»„é¢„æµ‹
    """
    print("\nğŸ§ª æµ‹è¯•4: æ•°ç»„é¢„æµ‹")
    try:
        # åˆ›å»ºæµ‹è¯•éŸ³é¢‘æ•°ç»„
        sample_rate = 16000
        duration = 3
        audio_array = np.random.randn(sample_rate * duration) * 0.1
        
        # é¢„æµ‹æƒ…ç»ª
        result = recognizer.predict_emotion_from_array(audio_array, sample_rate)
        
        if "error" in result:
            print(f"âŒ æ•°ç»„é¢„æµ‹å¤±è´¥: {result['error']}")
            return False
        
        print("âœ… æ•°ç»„é¢„æµ‹æˆåŠŸ")
        print(f"ğŸ¯ é¢„æµ‹æƒ…ç»ª: {result['predicted_emotion']}")
        print(f"ğŸ“Š ç½®ä¿¡åº¦: {result['confidence']:.3f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•°ç»„é¢„æµ‹æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_batch_prediction(recognizer):
    """
    æµ‹è¯•æ‰¹é‡é¢„æµ‹
    """
    print("\nğŸ§ª æµ‹è¯•5: æ‰¹é‡é¢„æµ‹")
    try:
        # åˆ›å»ºå¤šä¸ªæµ‹è¯•éŸ³é¢‘æ–‡ä»¶
        audio_paths = []
        for i in range(3):
            audio_path = create_test_audio(duration=2)
            audio_paths.append(audio_path)
        
        # æ‰¹é‡é¢„æµ‹
        results = recognizer.batch_predict(audio_paths)
        
        print(f"âœ… æ‰¹é‡é¢„æµ‹æˆåŠŸï¼Œå¤„ç†äº† {len(results)} ä¸ªæ–‡ä»¶")
        
        for i, result in enumerate(results):
            if "error" not in result:
                print(f"  æ–‡ä»¶ {i+1}: {result['predicted_emotion']} (ç½®ä¿¡åº¦: {result['confidence']:.3f})")
            else:
                print(f"  æ–‡ä»¶ {i+1}: å¤„ç†å¤±è´¥ - {result['error']}")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        for audio_path in audio_paths:
            os.unlink(audio_path)
        
        return True
        
    except Exception as e:
        print(f"âŒ æ‰¹é‡é¢„æµ‹æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_system_info():
    """
    æµ‹è¯•ç³»ç»Ÿä¿¡æ¯
    """
    print("\nğŸ§ª æµ‹è¯•6: ç³»ç»Ÿä¿¡æ¯")
    try:
        import torch
        print(f"âœ… PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"âœ… CUDAå¯ç”¨: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"âœ… CUDAç‰ˆæœ¬: {torch.version.cuda}")
            print(f"âœ… GPUæ•°é‡: {torch.cuda.device_count()}")
            print(f"âœ… å½“å‰GPU: {torch.cuda.get_device_name()}")
        
        import transformers
        print(f"âœ… Transformersç‰ˆæœ¬: {transformers.__version__}")
        
        import librosa
        print(f"âœ… Librosaç‰ˆæœ¬: {librosa.__version__}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿä¿¡æ¯æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """
    ä¸»æµ‹è¯•å‡½æ•°
    """
    print("ğŸ¤ è¯­éŸ³æƒ…ç»ªè¯†åˆ«ç³»ç»Ÿæµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•è®¡æ•°å™¨
    passed_tests = 0
    total_tests = 6
    
    # æµ‹è¯•1: æ¨¡å‹åŠ è½½
    recognizer = test_model_loading()
    if recognizer is not None:
        passed_tests += 1
    
    if recognizer is None:
        print("\nâŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæ— æ³•ç»§ç»­æµ‹è¯•")
        return
    
    # æµ‹è¯•2: éŸ³é¢‘é¢„å¤„ç†
    audio_path = test_audio_preprocessing(recognizer)
    if audio_path is not None:
        passed_tests += 1
    
    # æµ‹è¯•3: æƒ…ç»ªé¢„æµ‹
    if test_emotion_prediction(recognizer, audio_path):
        passed_tests += 1
    
    # æµ‹è¯•4: æ•°ç»„é¢„æµ‹
    if test_array_prediction(recognizer):
        passed_tests += 1
    
    # æµ‹è¯•5: æ‰¹é‡é¢„æµ‹
    if test_batch_prediction(recognizer):
        passed_tests += 1
    
    # æµ‹è¯•6: ç³»ç»Ÿä¿¡æ¯
    if test_system_info():
        passed_tests += 1
    
    # æµ‹è¯•æ€»ç»“
    print("\n" + "=" * 50)
    print("ğŸ“‹ æµ‹è¯•æ€»ç»“")
    print(f"âœ… é€šè¿‡æµ‹è¯•: {passed_tests}/{total_tests}")
    print(f"âŒ å¤±è´¥æµ‹è¯•: {total_tests - passed_tests}/{total_tests}")
    
    if passed_tests == total_tests:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿè¿è¡Œæ­£å¸¸ã€‚")
        print("\nğŸš€ ç°åœ¨å¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤å¯åŠ¨Webç•Œé¢:")
        print("   python web_interface.py")
        print("\nğŸ’» æˆ–è€…ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·:")
        print("   python cli_tool.py -f your_audio.wav")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®‰è£…å’Œé…ç½®ã€‚")
        print("\nğŸ”§ å»ºè®®æ£€æŸ¥:")
        print("   1. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        print("   2. ä¾èµ–åŒ…æ˜¯å¦æ­£ç¡®å®‰è£…")
        print("   3. æ˜¯å¦æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´")
        print("   4. Pythonç‰ˆæœ¬æ˜¯å¦å…¼å®¹")

if __name__ == "__main__":
    main() 